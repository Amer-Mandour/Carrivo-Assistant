"""
Ø®Ø¯Ù…Ø© Roadmaps - Ù„Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…Ø¹ Ø¯Ø¹Ù… Fuzzy Matching
"""

from typing import List, Dict, Optional
import logging
from difflib import SequenceMatcher
from ..database import get_supabase

logger = logging.getLogger(__name__)

class RoadmapService:
    """Ø®Ø¯Ù…Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Roadmaps Ù…Ø¹ Ø¨Ø­Ø« Ø°ÙƒÙŠ"""
    
    # Ø®Ø±ÙŠØ·Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© (Synonyms)
    SYNONYMS = {
        # AI/ML - ØªÙˆØ³ÙŠØ¹ ÙƒØ¨ÙŠØ±
        "Ø°ÙƒØ§Ø¡": ["ai", "artificial intelligence", "machine learning", "data scientist", "mlops"],
        "Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": ["ai", "artificial intelligence", "machine learning", "data scientist"],
        "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": ["ai", "artificial intelligence", "machine learning", "data scientist", "mlops"],
        "ai": ["artificial intelligence", "machine learning", "data scientist", "mlops", "data science"],
        "artificial intelligence": ["ai", "machine learning", "data scientist", "mlops"],
        "machine learning": ["ai", "data scientist", "mlops", "ml"],
        "ml": ["machine learning", "ai", "mlops", "data scientist"],
        "data science": ["ai", "data scientist", "machine learning"],
        "Ø¨ÙŠØ§Ù†Ø§Øª": ["data", "data scientist", "ai"],
        
        # Web Development
        "ÙˆÙŠØ¨": ["web", "frontend", "backend", "full stack"],
        "web": ["frontend", "backend", "full stack"],
        "ÙØ±ÙˆÙ†Øª": ["frontend", "react", "javascript"],
        "ÙØ±ÙˆÙ†Øª Ø§Ù†Ø¯": ["frontend", "react", "javascript", "web"],
        "ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯": ["frontend", "react", "javascript", "web"],
        "Ø§Ù„ÙØ±ÙˆÙ†Øª": ["frontend", "react", "javascript"],
        "frontend": ["react", "javascript", "web"],
        "Ø¨Ø§Ùƒ": ["backend", "node", "python", "java"],
        "Ø¨Ø§Ùƒ Ø§Ù†Ø¯": ["backend", "node", "python", "java", "web"],
        "Ø¨Ø§Ùƒ Ø¥Ù†Ø¯": ["backend", "node", "python", "java", "web"],
        "Ø§Ù„Ø¨Ø§Ùƒ": ["backend", "node", "python", "java"],
        "backend": ["node", "python", "java", "web"],
        "full stack": ["frontend", "backend", "web"],
        "ÙÙˆÙ„ Ø³ØªØ§Ùƒ": ["full stack", "frontend", "backend"],
        
        # Mobile
        "Ù…ÙˆØ¨Ø§ÙŠÙ„": ["mobile", "android", "flutter", "react native"],
        "mobile": ["android", "flutter", "react native"],
        "Ø§Ù†Ø¯Ø±ÙˆÙŠØ¯": ["android", "mobile"],
        "android": ["mobile"],
        "flutter": ["mobile"],
        
        # DevOps
        "Ø¯ÙŠÙ Ø§ÙˆØ¨Ø³": ["devops", "docker", "kubernetes"],
        "devops": ["docker", "kubernetes"],
        "docker": ["devops", "kubernetes"],
        "kubernetes": ["devops", "docker"],
        
        # Security
        "Ø§Ù…Ù†": ["security", "cyber security", "cyber"],
        "Ø§Ù…Ø§Ù†": ["security", "cyber security"],
        "security": ["cyber security", "cyber"],
        "cyber": ["security", "cyber security"],
        
        # Database
        "Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª": ["database", "sql", "mongodb", "postgresql"],
        "database": ["sql", "mongodb", "postgresql"],
        "sql": ["database", "postgresql"],
        "mongodb": ["database"],
        "postgresql": ["database", "sql"],
        
        # Design
        "ØªØµÙ…ÙŠÙ…": ["design", "ux"],
        "design": ["ux"],
        "ux": ["design"],
        
        # Blockchain
        "Ø¨Ù„ÙˆÙƒØªØ´ÙŠÙ†": ["blockchain"],
        "blockchain": ["web3"],
        "web3": ["blockchain"],
        
        # Programming Languages
        "python": ["backend", "ai", "data scientist"],
        "java": ["backend"],
        "javascript": ["frontend", "backend", "node"],
        "react": ["frontend"],
        "node": ["backend"],
        "go": ["backend"],
        "golang": ["go", "backend"],
    }
    
    def __init__(self):
        self.supabase = get_supabase()
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Ù†ØµÙŠÙ†"""
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def _expand_query(self, query: str) -> List[str]:
        """ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        query_lower = query.lower()
        expanded = [query_lower]
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù€ Synonyms
        for key, synonyms in self.SYNONYMS.items():
            if key in query_lower:
                expanded.extend(synonyms)
            for synonym in synonyms:
                if synonym in query_lower:
                    expanded.append(key)
                    expanded.extend(synonyms)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        return list(set(expanded))
    
    async def search_roadmaps(self, query: str, limit: int = 5, use_embeddings: bool = True) -> List[Dict]:
        """
        HYBRID SEARCH: Vector Embeddings (primary) + Fuzzy Matching (fallback)
        
        Search Flow:
        1. Try vector search using embeddings (if available)
        2. If vector search fails or returns poor results, fallback to fuzzy matching
        3. Return best results from either method
        
        Args:
            query: Search query text
            limit: Number of results to return
            use_embeddings: Whether to attempt vector search (default: True)
        
        Returns:
            List of roadmaps ranked by relevance
        """
        try:
            # ============================================================
            # PHASE 1: Vector Search (Primary Method)
            # ============================================================
            if use_embeddings:
                vector_results = await self._vector_search(query, limit)
                
                # If vector search succeeded with good results, use it
                if vector_results and len(vector_results) > 0:
                    # Check quality of top result
                    top_similarity = vector_results[0].get('similarity', 0)
                    
                    if top_similarity > 0.6:  # High confidence threshold
                        logger.info(f"âœ… Vector search succeeded (top similarity: {top_similarity:.2f})")
                        return vector_results
                    else:
                        logger.info(f"âš ï¸ Vector search returned low-confidence results (top: {top_similarity:.2f})")
            
            # ============================================================
            # PHASE 2: Fuzzy Matching Fallback
            # ============================================================
            logger.info("ğŸ”„ Falling back to fuzzy matching...")
            fuzzy_results = await self._fuzzy_search(query, limit)
            
            return fuzzy_results
            
        except Exception as e:
            logger.error(f"Error in hybrid search: {e}")
            # Last resort: try fuzzy matching
            return await self._fuzzy_search(query, limit)
    
    async def _vector_search(self, query: str, limit: int) -> List[Dict]:
        """
        Vector similarity search using Supabase RPC
        
        Args:
            query: Search query
            limit: Number of results
            
        Returns:
            List of roadmaps with similarity scores
        """
        try:
            # Import embedding service
            from .embedding_service import EmbeddingService
            embedding_service = EmbeddingService()
            
            # Check if embedding service is available
            if not embedding_service.is_available():
                logger.warning("Embedding service not available, skipping vector search")
                return []
            
            # Generate query embedding
            logger.info(f"Generating embedding for query: '{query[:50]}...'")
            query_embedding = await embedding_service.generate_embedding(query)
            
            if not query_embedding:
                logger.warning("Failed to generate query embedding")
                return []
            
            # Call Supabase RPC function for vector search
            result = self.supabase.rpc(
                'match_roadmaps',
                {
                    'query_embedding': query_embedding,
                    'match_count': limit,
                    'similarity_threshold': 0.5  # Minimum similarity
                }
            ).execute()
            
            if result.data:
                logger.info(f"Vector search found {len(result.data)} results")
                return result.data
            else:
                logger.info("Vector search returned no results")
                return []
                
        except Exception as e:
            logger.error(f"Vector search error: {e}")
            return []
    
    async def _fuzzy_search(self, query: str, limit: int) -> List[Dict]:
        """
        FALLBACK: Fuzzy matching search (original implementation)
        
        Args:
            query: Search query
            limit: Number of results
            
        Returns:
            List of roadmaps with similarity scores
        """
        try:
            # Get all roadmaps from database
            result = self.supabase.table("roadmaps").select("*").execute()
            all_roadmaps = result.data if result.data else []
            
            if not all_roadmaps:
                return []
            
            # -----------------------------------------------------------------
            # IMPROVEMENT: Try Client-Side Vector Search if embeddings exist
            # -----------------------------------------------------------------
            try:
                from .embedding_service import EmbeddingService
                embedding_service = EmbeddingService()
                
                # Check if we have embeddings in the fetched data
                if any(r.get('embedding') for r in all_roadmaps) and embedding_service.is_available():
                    logger.info("â„¹ï¸ Attempting client-side vector search on fetched roadmaps...")
                    # search_similar_roadmaps now implements proper vector cosine similarity
                    vector_results = await embedding_service.search_similar_roadmaps(query, all_roadmaps, limit, allow_fallback=False)
                    
                    if vector_results:
                        logger.info(f"âœ… Client-side vector search found {len(vector_results)} results")
                        return vector_results
            except Exception as vec_error:
                logger.warning(f"Client-side vector search failed, continuing to fuzzy match: {vec_error}")
            
            # -----------------------------------------------------------------
            # TEXT MATCHING (Original Logic)
            # -----------------------------------------------------------------
            
            # Expand query with synonyms
            expanded_queries = self._expand_query(query)
            
            scored_roadmaps = []
            for roadmap in all_roadmaps:
                max_score = 0
                
                # Clean text for matching
                title_clean = roadmap['title'].lower().replace('&', 'and').replace('-', ' ')
                desc_clean = roadmap.get('description', '').lower().replace('&', 'and').replace('-', ' ')
                cat_clean = roadmap.get('category', '').lower().replace('/', ' ').replace('-', ' ')
                
                searchable_text = f"{title_clean} {desc_clean} {cat_clean}"
                
                # Calculate maximum similarity score
                for exp_query in expanded_queries:
                    exp_query_clean = exp_query.replace('&', 'and').replace('-', ' ')
                    
                    # Direct match (highest score)
                    if exp_query_clean in searchable_text:
                        max_score = max(max_score, 1.0)
                        break
                    
                    # Partial match using SequenceMatcher
                    title_score = self._calculate_similarity(exp_query_clean, title_clean)
                    desc_score = self._calculate_similarity(exp_query_clean, desc_clean)
                    cat_score = self._calculate_similarity(exp_query_clean, cat_clean)
                    max_score = max(max_score, title_score, desc_score, cat_score)
                
                if max_score > 0.15:  # Minimum threshold
                    scored_roadmaps.append({
                        **roadmap,
                        'similarity_score': max_score,
                        'similarity': max_score  # Alias for consistency with vector search
                    })
            
            # Sort by similarity
            scored_roadmaps.sort(key=lambda x: x['similarity_score'], reverse=True)
            
            logger.info(f"Fuzzy search found {len(scored_roadmaps)} results")
            return scored_roadmaps[:limit]
            
        except Exception as e:
            logger.error(f"Fuzzy search error: {e}")
            return []
    
    async def get_roadmap_by_slug(self, slug: str) -> Optional[Dict]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Roadmap Ù…Ø­Ø¯Ø¯ Ø¨ÙˆØ§Ø³Ø·Ø© slug
        """
        try:
            result = self.supabase.table("roadmaps").select("*").eq("slug", slug).execute()
            return result.data[0] if result.data else None
        except Exception as e:
            logger.error(f"Error getting roadmap: {e}")
            return None
    
    async def get_all_roadmaps(self, category: Optional[str] = None) -> List[Dict]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ Roadmaps Ø£Ùˆ Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
        """
        try:
            query = self.supabase.table("roadmaps").select("*")
            
            if category:
                query = query.eq("category", category)
            
            result = query.execute()
            return result.data if result.data else []
        except Exception as e:
            logger.error(f"Error getting all roadmaps: {e}")
            return []
    
    async def get_categories(self) -> List[str]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        """
        try:
            result = self.supabase.table("roadmaps").select("category").execute()
            categories = list(set([r['category'] for r in result.data if r.get('category')]))
            return sorted(categories)
        except Exception as e:
            logger.error(f"Error getting categories: {e}")
            return []
